{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, widgets, interact\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scraped the data from the web and extracted only the relevant csv files. We have decided to focus on 4 languages: English, French, German and Italian. Furthermore, we included the data of all available languages on twitch.tv together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mogan/Desktop/data-visualization-project-2021-teamtwitch\n"
     ]
    }
   ],
   "source": [
    "%cd \"/home/mogan/Desktop/data-visualization-project-2021-teamtwitch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, language = \"\"):\n",
    "    filenames = glob.glob(path + \"/*.csv\")\n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        dfs.append(pd.read_csv(filename))\n",
    "\n",
    "    # concatenate all data into one DataFrame\n",
    "    df = pd.concat(dfs, ignore_index=True).dropna(axis=1)\n",
    "    # drop empty and single value columns \n",
    "    df = df.loc[:,df.apply(pd.Series.nunique) != 1]\n",
    "    # create a datetime column\n",
    "    df[\"date\"] = pd.to_datetime(df['year'].astype(str)  + df['month'], format='%Y%B')\n",
    "    df = df.drop(['year', 'month'], axis=1)\n",
    "    df = df.rename(columns={\"url\": \"channel\"})\n",
    "    \n",
    "    # Select only relevant columns\n",
    "    df_final = df[[\"channel\", \"date\", \"viewminutes\", \"streamedminutes\"]]\n",
    "    \n",
    "    # Add language\n",
    "    if language != \"\": df_final[\"language\"] = language \n",
    "    \n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = load_data(r'./data/All')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = load_data(r'./data/English', 'English')\n",
    "french = load_data(r'./data/French', 'French')\n",
    "german = load_data(r'./data/German', 'German')\n",
    "italian = load_data(r'./data/Italian', 'Italian')\n",
    "\n",
    "# For chess we need the data with the languages annotated\n",
    "en_fr_ge_it = english.append(german).append(french).append(italian)\n",
    "en_fr_ge_it = en_fr_ge_it.set_index(np.arange(len(en_fr_ge_it)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test = all_[all_.date ==\"2016-02-01\"]\n",
    "all_test\n",
    "all_test.to_csv(r\"./data/all_test.csv\", sep = \",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged csv as one big csv\n",
    "all_ = all_.sort_values(by=\"date\")\n",
    "all_.to_csv(r\"./data/all_.csv\", sep = \",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some basic stats about our dataset (all languages together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will mainly focus on the column **viewminutes**. Here is a random subset of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_.groupby([\"date\", \"channel\"]).sum().sample(5).sort_values(by=[\"viewminutes\"], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the magnitude of the viewminutes, we also show the statistics on a logscale (logviewminutes).\n",
    "In this summary we see that in the month with the most viewminutes, the amount of watched minutes were $~2\\cdot e^{10}$. Half of the available months have $~1.8\\cdot e^3$ or less viewminutes. This statistics hint at a skewed distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_[\"logviewminutes\"] = np.log10(all_['viewminutes']+1)\n",
    "all_.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising the viewminutes distribution (on a log scale), we notice indeed a skewed distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 5))\n",
    "all_[\"viewminutes\"] = all_[\"viewminutes\"].map(lambda x: x+1)\n",
    "sns.histplot(data = all_, x = \"viewminutes\", log_scale = True, ax = ax, bins = 100)\n",
    "ax.set_title(\"Distribution of monthly (log) viewminutes over all languages\")\n",
    "ax.set_xlabel(\"Viewminutes (on logscale)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we glance into our most recent data, to get an idea what kind of channels seem to be super popular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_.groupby([\"date\", \"channel\"]).sum().sort_values(by=[\"date\", \"viewminutes\"], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the n most popular channels over all languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to only focus on the most popular channels across all languages, but we are aware that this favours the popular channels among the english speaking languages, since they dominate the viewminutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_most_popular(df, n = 5, language = True):\n",
    "    \n",
    "    # Get the top n channels of all languages together\n",
    "    top_n = all_.groupby(\"channel\").sum()[\"viewminutes\"].sort_values(ascending=False).head(n)\n",
    "    top_n = list(top_n.index.values)\n",
    "    \n",
    "    # Extract the relevant data rows containing information about the top channels\n",
    "    if language:\n",
    "        temp = df[df['channel'].isin(top_n)][['viewminutes','date','channel', 'language']].sort_values(by=[\"channel\"])\n",
    "    else:\n",
    "        temp = df[df['channel'].isin(top_n)][['viewminutes','date','channel']].sort_values(by=[\"channel\"])\n",
    "        \n",
    "    log_x=True\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "pop_en_fr_ge = get_n_most_popular(en_fr_ge_it, n)\n",
    "pop_all = get_n_most_popular(all_, n, language = False)\n",
    "pop_all['language'] = \"All\"\n",
    "\n",
    "# append for plotting\n",
    "pop = pop_en_fr_ge.append(pop_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot timeseries of most popular channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot our data in an interactive way. To see the plot, just select your desired language in the box, or choose \"All\" to see the timeseries over all languages. You can hover over the graph to inspect it in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_most_popular(language):\n",
    "    if not language:\n",
    "        return\n",
    "    \n",
    "    # wrangle dataframe for plotting\n",
    "    df = pop[pop.language.isin([language[0]])]\n",
    "    df = df.drop_duplicates(keep='first')\n",
    "    df = df.pivot(index='date', columns='channel', values = 'viewminutes')\n",
    "    \n",
    "    # set up the plotly figure\n",
    "    fig = px.line(df)\n",
    "    fig.update_layout(hovermode=\"x\")\n",
    "    fig.update_layout(\n",
    "    title=f\"Viewminutes of the most popular channels on Twitch.tv in {language[0]}\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Viewminutes\",\n",
    "    legend_title=\"Channel\",\n",
    "    )\n",
    "    \n",
    "    # indicate the lockdown start italy with a vertical line\n",
    "    fig.add_vline(x=\"2020-03-09\")\n",
    "    fig.add_annotation(\n",
    "    x=\"2020-03-09\",\n",
    "    y=100,\n",
    "    text=\"Lockdowns in Europe start\",\n",
    "    textangle=-90\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_selector = widgets.SelectMultiple(\n",
    "    options = np.sort(pop.language.unique()),\n",
    "    description = 'Languages: '\n",
    ")\n",
    "\n",
    "_ = interact(plot_most_popular, language = language_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot timeseries of chess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also interested in how the chess channel developed over the years. We hypothesize, that the corona lockdowns (first was in Italy on 09.03.2020) and the release of the TV show \"Queen's Gambit\" (23.10.2020) have influenced its popularity, so we will mark these dates with a vertical line in our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chess(df):\n",
    "    chess_s = df[df[\"channel\"] == 'Chess'][[\"viewminutes\", \"date\", 'language']]\n",
    "    chess_s = chess_s.sort_values(by=[\"date\"])#.set_index(\"date\")\n",
    "    chess_s = chess_s.drop_duplicates(keep='first')\n",
    "    chess_s = chess_s.pivot(index='date', columns='language', values = 'viewminutes')\n",
    "    \n",
    "    # compute over all languages\n",
    "    chess_a = all_[all_[\"channel\"] == 'Chess']\n",
    "    chess_a = chess_a.sort_values(by=[\"date\"])#.set_index(\"date\")\n",
    "    chess_a = chess_a.drop_duplicates(keep='first')\n",
    "    chess_a = chess_a.pivot(index='date', columns='channel', values = 'viewminutes')\n",
    "    \n",
    "    # merge and reorder and rename for plotting\n",
    "    chess = pd.merge(chess_s, chess_a, left_index = True, right_index = True)\n",
    "    chess = chess.rename({\"Chess\":\"All\"}, axis='columns')\n",
    "    chess = chess[[\"All\", \"English\", \"French\", \"German\", \"Italian\"]]\n",
    "    \n",
    "    fig = px.line(chess)\n",
    "    fig.update_layout(hovermode=\"x\")\n",
    "    fig.update_layout(\n",
    "    title=f\"Viewminutes of the Chess channel on Twitch.tv in different languages\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Viewminutes\",\n",
    "    legend_title=\"Language\",\n",
    "    )\n",
    "    \n",
    "    # day of Queen's Gambit TV Show release (23.10.2020)\n",
    "    fig.add_vline(x=\"2020-10-23\")\n",
    "    fig.add_annotation(x=\"2020-10-23\", y=100,\n",
    "            text=\"Release of Queen's Gambit\",\n",
    "            textangle=-90)\n",
    "    \n",
    "    # lockdown start italy (09.03.2020)\n",
    "    fig.add_vline(x=\"2020-03-09\")\n",
    "    fig.add_annotation(\n",
    "    x=\"2020-03-09\",\n",
    "    y=100,\n",
    "    text=\"Lockdowns in Europe start\",\n",
    "    textangle=-90\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chess_fig = plot_chess(en_fr_ge_it)\n",
    "chess_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save chess df to csv\n",
    "chess_pd = all_[all_[\"channel\"] == 'Chess'].sort_values(by=\"date\")[[\"date\", \"viewminutes\"]]\n",
    "chess_pd.to_csv(r\"./data/chess.csv\", sep = \",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
